
@article{atari,
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    citeulike-article-id = {13527831},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature14236},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature14236},
    day = {26},
    doi = {10.1038/nature14236},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {artificial\_inteligence, control, machine\_learning, tweet},
    month = feb,
    number = {7540},
    pages = {529--533},
    posted-at = {2015-02-25 18:55:27},
    priority = {2},
    publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
    title = {Human-level control through deep reinforcement learning},
    url = {http://dx.doi.org/10.1038/nature14236},
    volume = {518},
    year = {2015}
}

@article{sutton1996generalization,
  title={Generalization in reinforcement learning: Successful examples using sparse coarse coding},
  author={Sutton, Richard S},
  journal={Advances in neural information processing systems},
  pages={1038--1044},
  year={1996},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}

@inproceedings{perez2014robot,
  title={Robot local navigation with learned social cost functions},
  author={P{\'e}rez-Higueras, No{\'e} and Ram{\'o}n-Vigo, Rafael and Caballero, Fernando and Merino, Luis},
  booktitle={Informatics in Control, Automation and Robotics (ICINCO), 2014 11th International Conference on},
  volume={2},
  pages={618--625},
  year={2014},
  organization={IEEE}
}

@misc{socialcogdef,
  title = {Research Areas in Social Psychology},
  howpublished = {\url{http://psychology.about.com/od/socialpsychology/p/socialresearch.htm}},
  note = {Accessed: 2015-31-3},
}

@article{bennett2015robotic,
  title={Robotic faces: Exploring dynamical patterns of social interaction between humans and robots},
  author={Bennett, Casey},
  year={2015},
  publisher={Indiana University}
}

@article{ngoinverse,
  title={Inverse Reinforcement Learning},
  author={Ngo, Vien and Toussaint, Marc}
}

@inproceedings{vasquez2014inverse,
  title={Inverse reinforcement learning algorithms and features for robot navigation in crowds: an experimental comparison},
  author={Vasquez, Dizan and Okal, Billy and Arras, Kai O},
  booktitle={Intelligent Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference on},
  pages={1341--1346},
  year={2014},
  organization={IEEE}
}

@misc{Eden,
  title = {Reinforcement Learning},
  howpublished = {\url{http://www.cse.unsw.edu.au/~cs9417ml/RL1/index.html}},
  note = {Accessed: 2015-11-22},
  author = {Tim Eden and Anthony Knittel and Raphael van Uffelen}
}

@misc{Greedy,
  title = {How to implement epsilon greedy strategy / policy},
  howpublished = {\url{https://junedmunshi.wordpress.com/2012/03/30/how-to-implement-epsilon-greedy-strategy-policy/}},
  note = {Accessed: 2015-11-21},
}
@article{o2003temporal,
  title={Temporal difference models and reward-related learning in the human brain},
  author={O'Doherty, John P and Dayan, Peter and Friston, Karl and Critchley, Hugo and Dolan, Raymond J},
  journal={Neuron},
  volume={38},
  number={2},
  pages={329--337},
  year={2003},
  publisher={Elsevier}
}
@article{peng2015mobile,
  title={Mobile Robot Path Planning Based on Improved Q Learning Algorithm},
  author={Peng, Jiansheng},
  journal={International Journal of Multimedia and Ubiquitous Engineering},
  volume={10},
  number={7},
  pages={285--294},
  year={2015}
}
@article{Watkins:1992,
 author = {Watkins, Christopher J. C. H. and Dayan, Peter},
 title = {Technical Note:  \cal Q-Learning},
 journal = {Mach. Learn.},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 issn = {0885-6125},
 pages = {279--292},
 numpages = {14},
 url = {http://dx.doi.org/10.1007/BF00992698},
 doi = {10.1007/BF00992698},
 acmid = {139618},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {\cal Q-learning, asynchronous dynamic programming, reinforcement learning, temporal differences},
} 
@inproceedings{sprague2003multiple,
  title={Multiple-goal reinforcement learning with modular sarsa (0)},
  author={Sprague, Nathan and Ballard, Dana},
  booktitle={IJCAI},
  pages={1445--1447},
  year={2003},
  organization={Citeseer}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  pages={663--670},
  year={2000}
}

@inproceedings{hamahata2008effective,
  title={Effective integration of imitation learning and reinforcement learning by generating internal reward},
  author={Hamahata, Keita and Taniguchi, Tadahiro and Sakakibara, Kazutoshi and Nishikawa, Ikuko and Tabuchi, Kazuma and Sawaragi, Tetsuo},
  booktitle={2008 Eighth International Conference on Intelligent Systems Design and Applications},
  volume={3},
  pages={121--126},
  year={2008},
  organization={IEEE}
}

@inproceedings{atkeson1997robot,
  title={Robot learning from demonstration},
  author={Atkeson, Christopher G and Schaal, Stefan},
  booktitle={ICML},
  volume={97},
  pages={12--20},
  year={1997}
}
@article{rothkopf2013modular,
  title={Modular inverse reinforcement learning for visuomotor behavior},
  author={Rothkopf, Constantin A and Ballard, Dana H},
  journal={Biological cybernetics},
  volume={107},
  number={4},
  pages={477--490},
  year={2013},
  publisher={Springer}
}

@article{kretzschmar2016socially,
  title={Socially compliant mobile robot navigation via inverse reinforcement learning},
  author={Kretzschmar, Henrik and Spies, Markus and Sprunk, Christoph and Burgard, Wolfram},
  journal={The International Journal of Robotics Research},
  pages={0278364915619772},
  year={2016},
  publisher={SAGE Publications}
}

@article{xia2016neural,
  title={Neural inverse reinforcement learning in autonomous navigation},
  author={Xia, Chen and El Kamel, Abdelkader},
  journal={Robotics and Autonomous Systems},
  year={2016},
  publisher={Elsevier}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1602.01783},
  year={2016}
}

@article{duan2016benchmarking,
  title={Benchmarking Deep Reinforcement Learning for Continuous Control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1604.06778},
  year={2016}
}

@article{wulfmeier2015maximum,
  title={Maximum Entropy Deep Inverse Reinforcement Learning},
  author={Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  journal={arXiv preprint arXiv:1507.04888},
  year={2015}
}

@misc{matiisen_2015, title={Guest Post (Part I): Demystifying Deep Reinforcement Learning - Nervana}, url={https://www.nervanasys.com/demystifying-deep-reinforcement-learning/}, journal={Nervana Systems}, publisher={Nervana Systems}, author={Matiisen, Tambet}, year={2015}, month={Dec}}


 @misc{jangir_2016, title={Apprenticeship learning using Inverse Reinforcement Learning}, url={https://jangirrishabh.github.io/2016/07/09/virtual-car-irl/}, journal={Apprenticeship learning using Inverse Reinforcement Learning}, author={Jangir, Rishabh}, year={2016}, month={Jul}} 

@article{Tesauro:1995,
 author = {Tesauro, Gerald},
 title = {Temporal Difference Learning and TD-Gammon},
 journal = {Commun. ACM},
 issue_date = {March 1995},
 volume = {38},
 number = {3},
 month = mar,
 year = {1995},
 issn = {0001-0782},
 pages = {58--68},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/203330.203343},
 doi = {10.1145/203330.203343},
 acmid = {203343},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@misc{tutorial,
  title = {Q-Learning By Examples},
  howpublished = {\url{http://people.revoledu.com/kardi/tutorial/ReinforcementLearning/}},
  note = {Accessed: 2015-11-15},
}

@inproceedings{ziebart2008maximum,
  title={Maximum Entropy Inverse Reinforcement Learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={AAAI},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@inproceedings{van2016deep,
  title={Deep Reinforcement Learning with Double Q-Learning.},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI},
  pages={2094--2100},
  year={2016}
}

@article{wang2015dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and van Hasselt, Hado and Lanctot, Marc and de Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}

@article{HausknechtDRQN,
  author    = {Matthew J. Hausknecht and
               Peter Stone},
  title     = {Deep Recurrent Q-Learning for Partially Observable MDPs},
  journal   = {CoRR},
  volume    = {abs/1507.06527},
  year      = {2015},
  url       = {http://arxiv.org/abs/1507.06527},
  timestamp = {Sun, 02 Aug 2015 18:42:02 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HausknechtS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{jin2015inverse,
  title={Inverse Reinforcement Learning via Deep Gaussian Process},
  author={Jin, Ming and Spanos, Costas},
  journal={arXiv preprint arXiv:1512.08065},
  year={2015}
}

@inproceedings{levine2011nonlinear,
  title={Nonlinear inverse reinforcement learning with gaussian processes},
  author={Levine, Sergey and Popovic, Zoran and Koltun, Vladlen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={19--27},
  year={2011}
}

@inproceedings{qiao2011inverse,
  title={Inverse reinforcement learning with Gaussian process},
  author={Qiao, Qifeng and Beling, Peter A},
  booktitle={American Control Conference (ACC), 2011},
  pages={113--118},
  year={2011},
  organization={IEEE}
}

@article{sharifzadeh2016learning,
  title={Learning to Drive using Inverse Reinforcement Learning and Deep Q-Networks},
  author={Sharifzadeh, Sahand and Chiotellis, Ioannis and Triebel, Rudolph and Cremers, Daniel},
  journal={arXiv preprint arXiv:1612.03653},
  year={2016}
}

@article{ramachandran2007bayesian,
  title={Bayesian inverse reinforcement learning},
  author={Ramachandran, Deepak and Amir, Eyal},
  journal={Urbana},
  volume={51},
  number={61801},
  pages={1--4},
  year={2007}
}

@phdthesis{markovikj2014deep,
  title={Deep Apprenticeship Learning for Playing Games},
  author={Markovikj, Dejan},
  year={2014},
  school={Department of Computer Science, University of Oxford}
}

@article{hester2017learning,
  title={Learning from Demonstrations for Real World Reinforcement Learning},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Sendonaris, Andrew and Dulac-Arnold, Gabriel and Osband, Ian and Agapiou, John and others},
  journal={arXiv preprint arXiv:1704.03732},
  year={2017}
}

@misc{maze_code, title={Random Maze Generator (Python recipe) by FB36 ActiveState Code (http://code.activestate.com/recipes/578356/)}, url={http://code.activestate.com/recipes/578356-random-maze-generator/}, journal={Random Maze Generator « Python recipes « ActiveState Code}}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={http://tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dan~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}



