
@article{atari,
    author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    citeulike-article-id = {13527831},
    citeulike-linkout-0 = {http://dx.doi.org/10.1038/nature14236},
    citeulike-linkout-1 = {http://dx.doi.org/10.1038/nature14236},
    day = {26},
    doi = {10.1038/nature14236},
    issn = {0028-0836},
    journal = {Nature},
    keywords = {artificial\_inteligence, control, machine\_learning, tweet},
    month = feb,
    number = {7540},
    pages = {529--533},
    posted-at = {2015-02-25 18:55:27},
    priority = {2},
    publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
    title = {Human-level control through deep reinforcement learning},
    url = {http://dx.doi.org/10.1038/nature14236},
    volume = {518},
    year = {2015}
}

@article{sutton1996generalization,
  title={Generalization in reinforcement learning: Successful examples using sparse coarse coding},
  author={Sutton, Richard S},
  journal={Advances in neural information processing systems},
  pages={1038--1044},
  year={1996},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}

@inproceedings{perez2014robot,
  title={Robot local navigation with learned social cost functions},
  author={P{\'e}rez-Higueras, No{\'e} and Ram{\'o}n-Vigo, Rafael and Caballero, Fernando and Merino, Luis},
  booktitle={Informatics in Control, Automation and Robotics (ICINCO), 2014 11th International Conference on},
  volume={2},
  pages={618--625},
  year={2014},
  organization={IEEE}
}

@misc{socialcogdef,
  title = {Research Areas in Social Psychology},
  howpublished = {\url{http://psychology.about.com/od/socialpsychology/p/socialresearch.htm}},
  note = {Accessed: 2015-31-3},
}

@article{bennett2015robotic,
  title={Robotic faces: Exploring dynamical patterns of social interaction between humans and robots},
  author={Bennett, Casey},
  year={2015},
  publisher={Indiana University}
}

@article{ngoinverse,
  title={Inverse Reinforcement Learning},
  author={Ngo, Vien and Toussaint, Marc}
}

@inproceedings{vasquez2014inverse,
  title={Inverse reinforcement learning algorithms and features for robot navigation in crowds: an experimental comparison},
  author={Vasquez, Dizan and Okal, Billy and Arras, Kai O},
  booktitle={Intelligent Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference on},
  pages={1341--1346},
  year={2014},
  organization={IEEE}
}

@misc{Eden,
  title = {Reinforcement Learning},
  howpublished = {\url{http://www.cse.unsw.edu.au/~cs9417ml/RL1/index.html}},
  note = {Accessed: 2015-11-22},
  author = {Tim Eden and Anthony Knittel and Raphael van Uffelen}
}

@misc{Greedy,
  title = {How to implement epsilon greedy strategy / policy},
  howpublished = {\url{https://junedmunshi.wordpress.com/2012/03/30/how-to-implement-epsilon-greedy-strategy-policy/}},
  note = {Accessed: 2015-11-21},
}
@article{o2003temporal,
  title={Temporal difference models and reward-related learning in the human brain},
  author={O'Doherty, John P and Dayan, Peter and Friston, Karl and Critchley, Hugo and Dolan, Raymond J},
  journal={Neuron},
  volume={38},
  number={2},
  pages={329--337},
  year={2003},
  publisher={Elsevier}
}
@article{peng2015mobile,
  title={Mobile Robot Path Planning Based on Improved Q Learning Algorithm},
  author={Peng, Jiansheng},
  journal={International Journal of Multimedia and Ubiquitous Engineering},
  volume={10},
  number={7},
  pages={285--294},
  year={2015}
}
@article{Watkins:1992,
 author = {Watkins, Christopher J. C. H. and Dayan, Peter},
 title = {Technical Note:  \cal Q-Learning},
 journal = {Mach. Learn.},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 issn = {0885-6125},
 pages = {279--292},
 numpages = {14},
 url = {http://dx.doi.org/10.1007/BF00992698},
 doi = {10.1007/BF00992698},
 acmid = {139618},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {\cal Q-learning, asynchronous dynamic programming, reinforcement learning, temporal differences},
} 
@inproceedings{sprague2003multiple,
  title={Multiple-goal reinforcement learning with modular sarsa (0)},
  author={Sprague, Nathan and Ballard, Dana},
  booktitle={IJCAI},
  pages={1445--1447},
  year={2003},
  organization={Citeseer}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  pages={663--670},
  year={2000}
}

@inproceedings{hamahata2008effective,
  title={Effective integration of imitation learning and reinforcement learning by generating internal reward},
  author={Hamahata, Keita and Taniguchi, Tadahiro and Sakakibara, Kazutoshi and Nishikawa, Ikuko and Tabuchi, Kazuma and Sawaragi, Tetsuo},
  booktitle={2008 Eighth International Conference on Intelligent Systems Design and Applications},
  volume={3},
  pages={121--126},
  year={2008},
  organization={IEEE}
}

@inproceedings{atkeson1997robot,
  title={Robot learning from demonstration},
  author={Atkeson, Christopher G and Schaal, Stefan},
  booktitle={ICML},
  volume={97},
  pages={12--20},
  year={1997}
}
@article{rothkopf2013modular,
  title={Modular inverse reinforcement learning for visuomotor behavior},
  author={Rothkopf, Constantin A and Ballard, Dana H},
  journal={Biological cybernetics},
  volume={107},
  number={4},
  pages={477--490},
  year={2013},
  publisher={Springer}
}

@article{kretzschmar2016socially,
  title={Socially compliant mobile robot navigation via inverse reinforcement learning},
  author={Kretzschmar, Henrik and Spies, Markus and Sprunk, Christoph and Burgard, Wolfram},
  journal={The International Journal of Robotics Research},
  pages={0278364915619772},
  year={2016},
  publisher={SAGE Publications}
}

@article{xia2016neural,
  title={Neural inverse reinforcement learning in autonomous navigation},
  author={Xia, Chen and El Kamel, Abdelkader},
  journal={Robotics and Autonomous Systems},
  year={2016},
  publisher={Elsevier}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1602.01783},
  year={2016}
}

@article{duan2016benchmarking,
  title={Benchmarking Deep Reinforcement Learning for Continuous Control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1604.06778},
  year={2016}
}

@article{wulfmeier2015maximum,
  title={Maximum Entropy Deep Inverse Reinforcement Learning},
  author={Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  journal={arXiv preprint arXiv:1507.04888},
  year={2015}
}

@misc{matiisen_2015, title={Guest Post (Part I): Demystifying Deep Reinforcement Learning - Nervana}, url={https://www.nervanasys.com/demystifying-deep-reinforcement-learning/}, journal={Nervana Systems}, publisher={Nervana Systems}, author={Matiisen, Tambet}, year={2015}, month={Dec}}


 @misc{jangir_2016, title={Apprenticeship learning using Inverse Reinforcement Learning}, url={https://jangirrishabh.github.io/2016/07/09/virtual-car-irl/}, journal={Apprenticeship learning using Inverse Reinforcement Learning}, author={Jangir, Rishabh}, year={2016}, month={Jul}} 

@article{Tesauro:1995,
 author = {Tesauro, Gerald},
 title = {Temporal Difference Learning and TD-Gammon},
 journal = {Commun. ACM},
 issue_date = {March 1995},
 volume = {38},
 number = {3},
 month = mar,
 year = {1995},
 issn = {0001-0782},
 pages = {58--68},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/203330.203343},
 doi = {10.1145/203330.203343},
 acmid = {203343},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@misc{tutorial,
  title = {Q-Learning By Examples},
  howpublished = {\url{http://people.revoledu.com/kardi/tutorial/ReinforcementLearning/}},
  note = {Accessed: 2015-11-15},
}

@inproceedings{ziebart2008maximum,
  title={Maximum Entropy Inverse Reinforcement Learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={AAAI},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}
